"""
GitHub Trending AI é¡¹ç›®æŠ“å–æ¨¡å—

è·å– GitHub Trending ä¸­çš„ AI ç›¸å…³é¡¹ç›®
"""

import logging
import re
from dataclasses import dataclass
from datetime import datetime
from typing import List, Optional

import requests
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)


# ============================================================================
# æ•°æ®ç»“æ„
# ============================================================================

@dataclass
class GithubProject:
    """GitHub é¡¹ç›®ä¿¡æ¯"""
    name: str           # é¡¹ç›®åç§° (owner/repo)
    url: str            # é¡¹ç›® URL
    description: str    # é¡¹ç›®æè¿°
    language: str       # ä¸»è¦è¯­è¨€
    stars: int          # Star æ•°é‡
    forks: int          # Fork æ•°é‡
    stars_today: int    # ä»Šæ—¥æ–°å¢ Star
    topics: List[str]   # æ ‡ç­¾åˆ—è¡¨


# ============================================================================
# AI ç›¸å…³å…³é”®è¯
# ============================================================================

AI_KEYWORDS = [
    # æ ¸å¿ƒæœ¯è¯­
    "llm", "gpt", "transformer", "neural", "deep-learning", "machine-learning",
    "ai", "ml", "nlp", "cv", "computer-vision", "natural-language",
    # æ¨¡å‹
    "bert", "llama", "mistral", "gemini", "claude", "chatgpt", "openai",
    "stable-diffusion", "diffusion", "gan", "vae",
    # æ¡†æ¶
    "pytorch", "tensorflow", "huggingface", "langchain", "llamaindex",
    # åº”ç”¨
    "chatbot", "rag", "agent", "embedding", "vector", "fine-tuning",
    "quantization", "inference",
]

AI_TOPICS = [
    "machine-learning", "deep-learning", "artificial-intelligence",
    "natural-language-processing", "computer-vision", "reinforcement-learning",
    "neural-network", "llm", "large-language-models", "generative-ai",
    "stable-diffusion", "transformers", "gpt", "chatgpt", "langchain",
]


# ============================================================================
# æŠ“å–å‡½æ•°
# ============================================================================

def fetch_github_trending(
    language: str = "python",
    since: str = "daily",
    max_results: int = 30,
) -> List[GithubProject]:
    """
    æŠ“å– GitHub Trending é¡¹ç›®
    
    Args:
        language: ç¼–ç¨‹è¯­è¨€ (python/javascript/...)
        since: æ—¶é—´èŒƒå›´ (daily/weekly/monthly)
        max_results: æœ€å¤§è¿”å›æ•°é‡
        
    Returns:
        GithubProject åˆ—è¡¨
    """
    url = f"https://github.com/trending/{language}?since={since}"
    
    try:
        logger.info(f"æŠ“å– GitHub Trending: {url}")
        
        # ç¦ç”¨ SSL è­¦å‘Š (ä»£ç†ç¯å¢ƒä¸‹å¯èƒ½éœ€è¦)
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        # verify=False è§£å†³ä»£ç† SSL è¯ä¹¦éªŒè¯é—®é¢˜
        response = requests.get(url, headers=headers, timeout=30, verify=False)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        projects = []
        articles = soup.select("article.Box-row")
        
        for article in articles[:max_results]:
            project = _parse_trending_article(article)
            if project:
                projects.append(project)
        
        logger.info(f"è·å–åˆ° {len(projects)} ä¸ª Trending é¡¹ç›®")
        return projects
        
    except requests.exceptions.RequestException as e:
        logger.error(f"GitHub Trending æŠ“å–å¤±è´¥: {e}")
        return []


def _parse_trending_article(article) -> Optional[GithubProject]:
    """è§£æå•ä¸ª Trending é¡¹ç›®"""
    try:
        # é¡¹ç›®åç§°å’Œ URL
        name_elem = article.select_one("h2 a")
        if not name_elem:
            return None
        
        name = name_elem.text.strip().replace("\n", "").replace(" ", "")
        url = "https://github.com" + name_elem.get("href", "")
        
        # æè¿°
        desc_elem = article.select_one("p")
        description = desc_elem.text.strip() if desc_elem else ""
        
        # è¯­è¨€
        lang_elem = article.select_one("[itemprop='programmingLanguage']")
        language = lang_elem.text.strip() if lang_elem else "Unknown"
        
        # Stars å’Œ Forks
        stats = article.select("a.Link--muted")
        stars = 0
        forks = 0
        
        for stat in stats:
            href = stat.get("href", "")
            text = stat.text.strip().replace(",", "")
            if "/stargazers" in href:
                stars = _parse_number(text)
            elif "/forks" in href:
                forks = _parse_number(text)
        
        # ä»Šæ—¥æ–°å¢
        stars_today_elem = article.select_one("span.d-inline-block.float-sm-right")
        stars_today = 0
        if stars_today_elem:
            match = re.search(r"(\d+)", stars_today_elem.text.replace(",", ""))
            if match:
                stars_today = int(match.group(1))
        
        return GithubProject(
            name=name,
            url=url,
            description=description,
            language=language,
            stars=stars,
            forks=forks,
            stars_today=stars_today,
            topics=[],  # éœ€è¦é¢å¤– API è°ƒç”¨è·å–
        )
        
    except Exception as e:
        logger.warning(f"è§£æé¡¹ç›®å¤±è´¥: {e}")
        return None


def _parse_number(text: str) -> int:
    """è§£ææ•°å­— (æ”¯æŒ k åç¼€)"""
    text = text.strip().lower()
    if "k" in text:
        return int(float(text.replace("k", "")) * 1000)
    try:
        return int(text)
    except ValueError:
        return 0


# ============================================================================
# ç­›é€‰å‡½æ•°
# ============================================================================

def filter_ai_projects(projects: List[GithubProject]) -> List[GithubProject]:
    """
    ç­›é€‰ AI ç›¸å…³é¡¹ç›®
    
    Args:
        projects: é¡¹ç›®åˆ—è¡¨
        
    Returns:
        ç­›é€‰åçš„ AI ç›¸å…³é¡¹ç›®
    """
    ai_projects = []
    
    for project in projects:
        # æ£€æŸ¥æè¿°å’Œåç§°æ˜¯å¦åŒ…å« AI å…³é”®è¯
        text = f"{project.name} {project.description}".lower()
        
        is_ai = False
        for keyword in AI_KEYWORDS:
            if keyword in text:
                is_ai = True
                break
        
        # æ£€æŸ¥ topics
        for topic in project.topics:
            if topic.lower() in AI_TOPICS:
                is_ai = True
                break
        
        if is_ai:
            ai_projects.append(project)
    
    logger.info(f"ç­›é€‰å‡º {len(ai_projects)} ä¸ª AI ç›¸å…³é¡¹ç›®")
    return ai_projects


def fetch_ai_trending(
    language: str = "python",
    since: str = "daily",  # åˆå§‹æ—¶é—´èŒƒå›´
    max_results: int = 10,
    min_results: int = 5,  # æœ€å°‘éœ€è¦çš„ç»“æœæ•°
) -> List[GithubProject]:
    """
    è·å– AI ç›¸å…³ Trending é¡¹ç›® (å¸¦ fallback æœºåˆ¶)
    
    å¦‚æœ "daily" è·å–çš„é¡¹ç›®ä¸è¶³ min_results ä¸ªï¼Œ
    åˆ™è‡ªåŠ¨å°è¯• "weekly" å’Œ "monthly"ã€‚
    
    Args:
        language: ç¼–ç¨‹è¯­è¨€
        since: åˆå§‹æ—¶é—´èŒƒå›´
        max_results: æœ€å¤§è¿”å›æ•°é‡
        min_results: æœ€å°‘éœ€è¦çš„ç»“æœæ•°
        
    Returns:
        AI ç›¸å…³é¡¹ç›®åˆ—è¡¨
    """
    timeframes = ["daily", "weekly", "monthly"]
    
    # ç¡®å®šèµ·å§‹ç´¢å¼•
    try:
        start_idx = timeframes.index(since)
    except ValueError:
        start_idx = 0
    
    # æŒ‰é¡ºåºå°è¯•è·å– (daily -> weekly -> monthly)
    for tf in timeframes[start_idx:]:
        logger.info(f"æ­£åœ¨å°è¯•è·å– {tf} Trending...")
        
        # è·å–æ‰€æœ‰ Trending (å¤šæŠ“å–ä¸€äº›ä»¥ä¾¿è¿‡æ»¤)
        all_projects = fetch_github_trending(language, tf, max_results * 4)
        
        # ç­›é€‰ AI ç›¸å…³
        ai_projects = filter_ai_projects(all_projects)
        
        # å¦‚æœæ•°é‡è¶³å¤Ÿï¼Œç›´æ¥è¿”å›
        if len(ai_projects) >= min_results:
            logger.info(f"âœ… {tf} è·å–åˆ°è¶³å¤Ÿçš„ AI é¡¹ç›® ({len(ai_projects)} ä¸ª)")
            return ai_projects[:max_results]
        else:
            logger.warning(f"âš ï¸ {tf} AI é¡¹ç›®ä¸è¶³ ({len(ai_projects)} < {min_results})ï¼Œå°è¯•æ›´å¤§èŒƒå›´...")
    
    # å¦‚æœéƒ½å°è¯•å®Œäº†è¿˜æ˜¯ä¸è¶³ï¼Œå°±è¿”å›æœ€åä¸€æ¬¡çš„ç»“æœ
    logger.warning("æ‰€æœ‰æ—¶é—´èŒƒå›´å°è¯•å®Œæ¯•ï¼Œè¿”å›æœ€ç»ˆç»“æœ")
    return ai_projects[:max_results]


# ============================================================================
# æµ‹è¯•
# ============================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    projects = fetch_ai_trending(max_results=5)
    
    for p in projects:
        print(f"\n{p.name}")
        print(f"  â­ {p.stars} (+{p.stars_today} today)")
        print(f"  ğŸ“ {p.description[:100]}...")
